<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-post-page plugin-blog plugin-id-default">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.2.0">
<title data-rh="true">The speech-in-noise problem part two | The Clarity Project</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://claritychallenge.github.io/blog/The speech-in-noise problem part two"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docusaurus_tag" content="default"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docsearch:docusaurus_tag" content="default"><meta data-rh="true" property="og:title" content="The speech-in-noise problem part two | The Clarity Project"><meta data-rh="true" name="description" content="How hearing aids address the problem of speech-in-noise in noisy and quieter places. We’ll also discuss what machine learning techniques are often used for noise reduction, and some promising strategies for hearing aids."><meta data-rh="true" property="og:description" content="How hearing aids address the problem of speech-in-noise in noisy and quieter places. We’ll also discuss what machine learning techniques are often used for noise reduction, and some promising strategies for hearing aids."><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2020-07-06T00:00:00.000Z"><meta data-rh="true" property="article:author" content="https://www.salford.ac.uk/our-staff/simone-graetzer,http://trevorcox.me/trevor-cox"><meta data-rh="true" property="article:tag" content="machine learning,speech-in-noise"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://claritychallenge.github.io/blog/The speech-in-noise problem part two"><link data-rh="true" rel="alternate" href="https://claritychallenge.github.io/blog/The speech-in-noise problem part two" hreflang="en"><link data-rh="true" rel="alternate" href="https://claritychallenge.github.io/blog/The speech-in-noise problem part two" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="The Clarity Project RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="The Clarity Project Atom Feed">

<link rel="preconnect" href="https://www.google-analytics.com">
<script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-198878187-1","auto"),ga("set","anonymizeIp",!0),ga("send","pageview")</script>
<script async src="https://www.google-analytics.com/analytics.js"></script>






<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons"><link rel="stylesheet" href="/assets/css/styles.dfc13153.css">
<link rel="preload" href="/assets/js/runtime~main.458662d2.js" as="script">
<link rel="preload" href="/assets/js/main.ed05c70f.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#docusaurus_skipToContent_fallback">Skip to main content</a></div><nav class="navbar navbar--fixed-top navbarHideable_m1mJ"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.png" alt="Clarity Logo" class="themedImage_ToTc themedImage--light_HNdA"><img src="/img/logo.png" alt="Clarity Logo" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">Clarity</b></a><div class="navbar__item dropdown dropdown--hoverable"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">Shortcuts</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/docs/icassp2023/icassp2023_intro">I want to learn more about the ICASSP challenge...</a></li><li><a class="dropdown__link" href="/docs/icassp2023/icassp2023_download">I want to download the data...</a></li><li><a href="https://github.com/claritychallenge/clarity" target="_blank" rel="noopener noreferrer" class="dropdown__link">I want to see the code on GitHub...<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li><a class="dropdown__link" href="/docs/icassp2023/taking_part/icassp2023_registration">I want to register a team...</a></li><li><a class="dropdown__link" href="/docs/icassp2023/taking_part/icassp2023_submission">I want to submit results...</a></li></ul></div></div><div class="navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">Workshops</a><ul class="dropdown__menu"><li><a href="https://claritychallenge.github.io/clarity2022-CEC2-workshop/" target="_blank" rel="noopener noreferrer" class="dropdown__link">Clarity CEC2 2022, Dec<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li><a href="https://claritychallenge.github.io/clarity2022-workshop/" target="_blank" rel="noopener noreferrer" class="dropdown__link">Clarity 2022, Jun<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li><a href="https://claritychallenge.github.io/clarity2021-workshop/" target="_blank" rel="noopener noreferrer" class="dropdown__link">Clarity 2021<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">Challenges</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/docs/icassp2023/icassp2023_intro">ICASSP 2023 Grand Challenge (current)</a></li><li><a class="dropdown__link" href="/docs/cec2/cec2_intro">CEC2 (workshop in December)</a></li><li><a class="dropdown__link" href="/docs/cpc1/cpc1_intro">CPC1</a></li><li><a class="dropdown__link" href="/docs/cec1/cec1_intro">CEC1</a></li><li><a class="dropdown__link" href="/timeline">Future Challenges</a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">Software</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/tutorials">Tutorials</a></li><li><a href="https://github.com/claritychallenge/clarity" target="_blank" rel="noopener noreferrer" class="dropdown__link">GitHub<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">About Us</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/about">About Us</a></li><li><a class="dropdown__link" href="/contact">Contact Us</a></li><li><a class="dropdown__link" href="/timeline">Project timeline</a></li></ul></div><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/blog">Blog</a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"><div class="navbar__search"><span aria-label="expand searchbar" role="button" class="search-icon" tabindex="0"></span><input type="search" id="search_input_react" placeholder="Search" aria-label="Search" class="navbar__search-input search-bar"></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_re4s thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_pO2u margin-bottom--md">Recent posts</div><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/Announcement of ICASSP 2023 Grand Challenge">Announcement of ICASSP 2023 Grand Challenge</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/CPC1 results and prizes">CPC1 results and prizes</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/CEC2 registration open">CEC2 registration open</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/release of CEC2 baseline">Release of CEC2 baseline</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/launch of CEC2">Launch of CEC2</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/Jan-2-live-events">Live events in January</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/webinar-1-link">Introduction Webinar - Recording Available</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/welcome to CPC1">Welcome to CPC1</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/CEC1 submissions received">CEC1 submissions received</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/CEC1 eval data released">CEC1 eval data released</a></li></ul></nav></aside><main class="col col--7" itemscope="" itemtype="http://schema.org/Blog"><article itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h1 class="title_f1Hy" itemprop="headline">The speech-in-noise problem part two</h1><div class="container_mt6G margin-vert--md"><time datetime="2020-07-06T00:00:00.000Z" itemprop="datePublished">July 6, 2020</time> · <!-- -->5 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://www.salford.ac.uk/our-staff/simone-graetzer" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="https://avatars.githubusercontent.com/sgraetzer" alt="Simone Graetzer"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://www.salford.ac.uk/our-staff/simone-graetzer" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Simone Graetzer</span></a></div><small class="avatar__subtitle" itemprop="description">Clarity Team Member</small></div></div></div><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="http://trevorcox.me/trevor-cox" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="https://avatars.githubusercontent.com/trevorjcox" alt="Trevor Cox"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="http://trevorcox.me/trevor-cox" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Trevor Cox</span></a></div><small class="avatar__subtitle" itemprop="description">Clarity Team Member</small></div></div></div></div></header><div id="post-content" class="markdown" itemprop="articleBody"><p>How hearing aids address the problem of speech-in-noise in noisy and quieter places. We’ll also discuss what machine learning techniques are often used for noise reduction, and some promising strategies for hearing aids.</p><p><img loading="lazy" alt="Tablet user" src="/assets/images/UoN_HS-08207-1536x1024-c3cb2429eb9f80e07fc15a97b1ede0c1.jpeg" width="1536" height="1024" class="img_ev3q"></p><p>In a previous blog, we set out the problem of using hearing aids to pick out speech in noisy places. When the <a href="https://en.wikipedia.org/wiki/Signal-to-noise_ratio" target="_blank" rel="noopener noreferrer">signal-to-noise ratio (SNR)</a> is low, hearing aids can only do so much to improve the intelligibility of the speech.</p><p>A solitary hearing aid has various ways of addressing everyday constant noises such as cars, vacuum cleaners and fans. The aids work best when the noise is not too intrusive and SNR is relatively high. Problems arise when the noise is high (low SNRs), because then the hearing aid processing can distort the sound too much. While the hearing aid might have limited success in improving intelligibility in certain cases, they can still make the noise less annoying (e.g., Brons et al., 2014).</p><p>Using multiple microphones on each hearing aid can help in noisy conditions. The sound from the microphones is combined in a way that boosts the speech relative to the noise. This technology can be put into larger hearing aids, when there is enough spacing between the front and rear microphones.</p><p>One of the reasons why our brains are really good at picking out speech from the hubbub of a restaurant, is that it compares and contrasts the sounds from both ears. Our hearing is <a href="https://en.wikipedia.org/wiki/Binaural" target="_blank" rel="noopener noreferrer">binaural</a>. Similarly, if you have a hearing aids in both ears, they work better if they collaborate on reducing the noise.</p><p>Crucial to how our brains locate sound and pick out speech in noise are timing and level cues that come from comparing the sound at both ears. When sound comes from the side:</p><ul><li>interaural time differences occur because the sound arrives at one ear earlier than the other.</li><li>interaural level differences occur because the sound has to bend around the head to reach the furthest ear.</li></ul><p>Binaural hearing aids communicate wirelessly and use noise reduction strategies that preserve these interaural time and level difference cues (e.g., Van den Bogaert et al., 2009). This allows the listener’s brain to better locate the speech and boost this compared to the noise.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="machine-learning">Machine learning<a class="hash-link" href="#machine-learning" title="Direct link to heading">​</a></h2><p>In recent years, there has been increasing interest in what <a href="https://en.wikipedia.org/wiki/Machine_learning" target="_blank" rel="noopener noreferrer">machine learning</a> methods can do for hearing aids. Machine learning is a branch of artificial intelligence where computers learn directly from example data. One machine learning method is the neural network. This is an algorithm formed from layers of simple computational units connected to each other in a way that is inspired by connections between neurons in the brain. Deep (3+ layer) neural networks are able to learn complex, non-linear mapping functions, which makes them ideal candidates for noise reduction tasks.</p><p>We anticipate that machine learning can help tackle the challenge of speech in noise for hearing aids, providing a tailored solution for each individual and listening situation. For example, one thing machine learning could do is to sense the acoustic environment the listener is in, and choose the most suitable processing settings.</p><p><img loading="lazy" alt="Electronic brain" src="/assets/images/neural_brain-5ff559452f28c8fa0d411e6e67baee7a.jpeg" width="400" height="320" class="img_ev3q"></p><p>Image via <a href="http://www.vpnsrus.com" target="_blank" rel="noopener noreferrer">www.vpnsrus.com</a></p><p>In recent years, a machine learning approach for noise reduction has become popular. Neural networks are used to estimate time-frequency masks (a set of gains for each time-frequency unit that, when multiplied by the signal, produce less noisy speech; see, e.g., Zhao et al., 2018).</p><p>Machine learning systems for noise reduction are trained on artificially mixed speech and noise. Some operate on a single channel, i.e., using spectral cues, and some work with multiple channels using spatial cues. We expect that future hearing aids built on machine learning will perform best if they combine the left and right microphones to work binaurally.</p><p>Most of these noise reduction systems have been designed and evaluated in an off-line mode where they process pre-recorded signals. This isn’t much use for hearing aids that need to work in real-time with low latency (i.e., short delays). One challenge for hearing aids is to redesign off-line approaches to work quickly enough without too much loss of performance.</p><p>The potential for machine learning to produce better approaches to hearing aid processing is what motivated the Clarity Project. If you’re interested in hearing more as the challenges develop, please sign up.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="references">References<a class="hash-link" href="#references" title="Direct link to heading">​</a></h2><ul><li>Brons, I., Houben, R., and Dreschler, W. A. (2014). Effects of noise reduction on speech intelligibility, perceived listening effort, and personal preference in hearing-impaired listeners. <em>Trends in hearing</em>, 18, 1-10.</li><li>Van den Bogaert, T., Doclo, S., Wouters, J., and Moonen, M. (2009). Speech enhancement with multichannel Wiener filter techniques in multimicrophone binaural hearing aids. <em>The Journal of the Acoustical Society of America</em>, 125(1), 360-371.</li><li>Zhao, Y., Wang, D., Johnson, E. M., and Healy, E. W. (2018). A deep learning based segregation algorithm to increase speech intelligibility for hearing-impaired listeners in reverberant-noisy conditions. <em>The Journal of the Acoustical Society of America</em>, 144(3), 1627-1637.</li></ul><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="credits">Credits<a class="hash-link" href="#credits" title="Direct link to heading">​</a></h2><p>Photograph of hearing aid wearer, copyright University of Nottingham.</p><p>Image of brain with overlaid circuity made available by <a href="http://www.vpnsrus.com" target="_blank" rel="noopener noreferrer">www.vpnsrus.com</a>.</p></div><footer class="row docusaurus-mt-lg blogPostFooterDetailsFull_mRVl"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/machine-learning">machine learning</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/speech-in-noise">speech-in-noise</a></li></ul></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Blog post page navigation"><a class="pagination-nav__link pagination-nav__link--prev" href="/blog/One approach to our enhancement challenge"><div class="pagination-nav__sublabel">Newer Post</div><div class="pagination-nav__label">One approach to our enhancement challenge</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/blog/Hearing loss simulation"><div class="pagination-nav__sublabel">Older Post</div><div class="pagination-nav__label">Hearing loss simulation</div></a></nav></main><div class="col col--2"><div class="tableOfContents_bqdL thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#machine-learning" class="table-of-contents__link toc-highlight">Machine learning</a></li><li><a href="#references" class="table-of-contents__link toc-highlight">References</a></li><li><a href="#credits" class="table-of-contents__link toc-highlight">Credits</a></li></ul></div></div></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/cec2/cec2_intro">CEC2 Documentation</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/cpc1/cpc1_intro">CPC1 Documentation</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/cec1/cec1_intro">CEC1 Documentation</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/icassp2023/icassp2023_intro">CASSP 2023 Documentation</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="http://claritychallenge.org" target="_blank" rel="noopener noreferrer" class="footer__link-item">The Clarity Project<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://groups.google.com/g/clarity-challenge" target="_blank" rel="noopener noreferrer" class="footer__link-item">Clarity Google Group<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="mailto:claritychallengecontact@gmail.com" target="_blank" rel="noopener noreferrer" class="footer__link-item">Email Us<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/blog">Challenge Updates</a></li><li class="footer__item"><a href="https://github.com/claritychallenge/clarity" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2023 The Clarity Team. Built with Docusaurus.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.458662d2.js"></script>
<script src="/assets/js/main.ed05c70f.js"></script>
</body>
</html>