"use strict";(self.webpackChunkclarity_cec_1=self.webpackChunkclarity_cec_1||[]).push([[3051],{3905:(e,t,n)=>{n.d(t,{Zo:()=>u,kt:()=>d});var r=n(67294);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function o(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,r,a=function(e,t){if(null==e)return{};var n,r,a={},i=Object.keys(e);for(r=0;r<i.length;r++)n=i[r],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(r=0;r<i.length;r++)n=i[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var s=r.createContext({}),c=function(e){var t=r.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):o(o({},t),e)),n},u=function(e){var t=c(e.components);return r.createElement(s.Provider,{value:t},e.children)},h={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},p=r.forwardRef((function(e,t){var n=e.components,a=e.mdxType,i=e.originalType,s=e.parentName,u=l(e,["components","mdxType","originalType","parentName"]),p=c(n),d=a,m=p["".concat(s,".").concat(d)]||p[d]||h[d]||i;return n?r.createElement(m,o(o({ref:t},u),{},{components:n})):r.createElement(m,o({ref:t},u))}));function d(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var i=n.length,o=new Array(i);o[0]=p;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l.mdxType="string"==typeof e?e:a,o[1]=l;for(var c=2;c<i;c++)o[c]=n[c];return r.createElement.apply(null,o)}return r.createElement.apply(null,n)}p.displayName="MDXCreateElement"},65178:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>s,contentTitle:()=>o,default:()=>h,frontMatter:()=>i,metadata:()=>l,toc:()=>c});var r=n(87462),a=(n(67294),n(3905));const i={slug:"Clarity Challenge pre-announcement",title:"Clarity Challenge pre-announcement",author:"Trevor Cox",author_title:"Clarity Team Member",author_url:"http://trevorcox.me/trevor-cox",author_image_url:"https://avatars.githubusercontent.com/trevorjcox",tags:["CEC1"]},o=void 0,l={permalink:"/blog/Clarity Challenge pre-announcement",source:"@site/blog/2020-11-24-clarity-challenge-pre-announcement.md",title:"Clarity Challenge pre-announcement",description:"Although age-related hearing loss affects 40% of 55 to 74 year-olds, the majority of adults who would benefit from hearing aids don\u2019t use them. A key reason is simply that hearing aids don\u2019t provide enough benefit.",date:"2020-11-24T00:00:00.000Z",formattedDate:"November 24, 2020",tags:[{label:"CEC1",permalink:"/blog/tags/cec-1"}],readingTime:2.975,hasTruncateMarker:!0,authors:[{name:"Trevor Cox",title:"Clarity Team Member",url:"http://trevorcox.me/trevor-cox",imageURL:"https://avatars.githubusercontent.com/trevorjcox"}],frontMatter:{slug:"Clarity Challenge pre-announcement",title:"Clarity Challenge pre-announcement",author:"Trevor Cox",author_title:"Clarity Team Member",author_url:"http://trevorcox.me/trevor-cox",author_image_url:"https://avatars.githubusercontent.com/trevorjcox",tags:["CEC1"]},prevItem:{title:"Latency, computation time and real-time operation",permalink:"/blog/Latency, computation time and real-time operation"},nextItem:{title:"One approach to our enhancement challenge",permalink:"/blog/One approach to our enhancement challenge"}},s={authorsImageUrls:[void 0]},c=[{value:"The Task",id:"the-task",level:2},{value:"What will be provided",id:"what-will-be-provided",level:2},{value:"Important Dates",id:"important-dates",level:2},{value:"Further information",id:"further-information",level:2},{value:"Organisers",id:"organisers",level:2},{value:"Acknowledgement",id:"acknowledgement",level:2}],u={toc:c};function h(e){let{components:t,...i}=e;return(0,a.kt)("wrapper",(0,r.Z)({},u,i,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Although age-related hearing loss affects 40% of 55 to 74 year-olds, the majority of adults who would benefit from hearing aids don\u2019t use them. A key reason is simply that hearing aids don\u2019t provide enough benefit."),(0,a.kt)("p",null,"Picking out speech from background noise is a critical problem even for the most sophisticated devices. The purpose of the Clarity Challenges is to catalyse new work to radically improve the speech intelligibility provided by hearing aids."),(0,a.kt)("p",null,"The series of challenges will consider increasingly complex listening scenarios. The first round, launching in January 2021, will focus on speech in indoor environments in the presence of a single interferer. It will begin with a challenge involving improving hearing aid processing. Future challenges on how to model speech-in-noise perception will be launched at a later date."),(0,a.kt)("p",null,(0,a.kt)("img",{alt:"Person using tablet",src:n(90566).Z,width:"1536",height:"1024"})),(0,a.kt)("h2",{id:"the-task"},"The Task"),(0,a.kt)("p",null,"You will be provided with simulated scenes, each including a target speaker and interfering noise. For each scene, there will be signals that simulate those captured by a behind-the-ear hearing aid with three channels at each ear and those captured at the eardrum without a hearing aid present.  The target speech will be a short sentence and the interfering noise will be either speech or domestic appliance noise."),(0,a.kt)("p",null,"The task will be to deliver a hearing aid signal processing algorithm that can improve the intelligibility of the target speaker for a specified hearing-impaired listener. Initially, entries will be evaluated using an objective speech intelligibility measure we will provide. Subsequently, up to twenty of the most promising systems will be evaluated by a panel of listeners."),(0,a.kt)("p",null,"We will provide a baseline system so that teams can choose to focus on individual components or to develop their own complete pipelines."),(0,a.kt)("h2",{id:"what-will-be-provided"},"What will be provided"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Evaluation of the best entries by a panel of hearing-impaired listeners."),(0,a.kt)("li",{parentName:"ul"},"Speech + interferer scenes for training and evaluation."),(0,a.kt)("li",{parentName:"ul"},"An entirely new database of 10,000 spoken sentences"),(0,a.kt)("li",{parentName:"ul"},"Listener characterisations including audiograms and speech-in-noise testing."),(0,a.kt)("li",{parentName:"ul"},"Software including tools for generating training data, a baseline hearing aid algorithm, a baseline model of hearing impairment, and a binaural objective intelligibility measure.")),(0,a.kt)("h2",{id:"important-dates"},"Important Dates"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"January 2021 \u2013 Challenge launch and release of software and data"),(0,a.kt)("li",{parentName:"ul"},"April 2021 \u2013  Evaluation data released"),(0,a.kt)("li",{parentName:"ul"},"May 2021 \u2013 Submission deadline"),(0,a.kt)("li",{parentName:"ul"},"June-August 2021  \u2013 Listening test evaluation period"),(0,a.kt)("li",{parentName:"ul"},"September 2021 \u2013 Results announced at a Clarity Challenge Workshop in conjunction with Interspeech 2021")),(0,a.kt)("p",null,"Challenge and workshop participants will be invited to contribute to a journal Special Issue on the topic of Machine Learning for Hearing Aid Processing that will be announced next year."),(0,a.kt)("h2",{id:"further-information"},"Further information"),(0,a.kt)("p",null,"If you are interested in participating and wish to receive further information, please sign up."),(0,a.kt)("p",null,"If you have questions, contact us directly at ",(0,a.kt)("a",{parentName:"p",href:"mailto:contact@claritychallenge.org"},"contact@claritychallenge.org")),(0,a.kt)("h2",{id:"organisers"},"Organisers"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Prof. Jon P. Barker, Department of Computer Science, University of Sheffield"),(0,a.kt)("li",{parentName:"ul"},"Prof. Michael A. Akeroyd, Hearing Sciences, School of Medicine, University of Nottingham"),(0,a.kt)("li",{parentName:"ul"},"Prof. Trevor J. Cox, Acoustics Research Centre, University of Salford"),(0,a.kt)("li",{parentName:"ul"},"Prof. John F. Culling, School of Psychology, Cardiff University"),(0,a.kt)("li",{parentName:"ul"},"Prof. Graham Naylor, Hearing Sciences, School of Medicine, University of Nottingham"),(0,a.kt)("li",{parentName:"ul"},"Dr Simone Graetzer, Acoustics Research Centre, University of Salford"),(0,a.kt)("li",{parentName:"ul"},"Dr Rhoddy Viveros Mu\xf1oz, School of Psychology, Cardiff University"),(0,a.kt)("li",{parentName:"ul"},"Eszter Porter, Hearing Sciences, School of Medicine, University of Nottingham")),(0,a.kt)("p",null,"Funded by the Engineering and Physical Sciences Research Council (EPSRC), UK."),(0,a.kt)("p",null,"Supported by RNID (formerly Action on Hearing Loss), Hearing Industry Research Consortium, Amazon TTS Research, Honda Research Institute Europe."),(0,a.kt)("h2",{id:"acknowledgement"},"Acknowledgement"),(0,a.kt)("p",null,"The image copyright is owned by the University of Nottingham."))}h.isMDXComponent=!0},90566:(e,t,n)=>{n.d(t,{Z:()=>r});const r=n.p+"assets/images/UoN_HS-08207-1536x1024-c3cb2429eb9f80e07fc15a97b1ede0c1.jpeg"}}]);