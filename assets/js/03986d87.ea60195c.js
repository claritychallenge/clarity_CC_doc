"use strict";(self.webpackChunkclarity=self.webpackChunkclarity||[]).push([[1986],{16934:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>h,contentTitle:()=>d,default:()=>f,frontMatter:()=>l,metadata:()=>c,toc:()=>u});var a=n(74848),r=n(28453),i=n(11470),s=n(19365),o=n(86025);const l={id:"cec3_task1_data",title:"Task 1 Data",sidebar_label:"Data",sidebar_position:20},d=void 0,c={id:"cec3/task_1/cec3_task1_data",title:"Task 1 Data",description:"The data download contains the following directories for Task 2:",source:"@site/docs/cec3/task_1/task1_data.mdx",sourceDirName:"cec3/task_1",slug:"/cec3/task_1/cec3_task1_data",permalink:"/docs/cec3/task_1/cec3_task1_data",draft:!1,unlisted:!1,tags:[],version:"current",sidebarPosition:20,frontMatter:{id:"cec3_task1_data",title:"Task 1 Data",sidebar_label:"Data",sidebar_position:20},sidebar:"tutorialSidebar_cec3",previous:{title:"Overview",permalink:"/docs/cec3/task_1/cec3_task1_overview"},next:{title:"Rules",permalink:"/docs/cec3/task_1/task1_rules"}},h={},u=[{value:"Recording setup",id:"recording-setup",level:2},{value:"The Hearing Aid signal simulation",id:"the-hearing-aid-signal-simulation",level:2},{value:"Audio Data format",id:"audio-data-format",level:2},{value:"Metadata Formats",id:"metadata-formats",level:2},{value:"The Room Metadata",id:"the-room-metadata",level:3},{value:"The Scene Metadata",id:"the-scene-metadata",level:3}];function m(e){const t={a:"a",code:"code",h2:"h2",h3:"h3",li:"li",p:"p",pre:"pre",ul:"ul",...(0,r.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(t.p,{children:"The data download contains the following directories for Task 2:"}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-text",children:"clarity_CEC3_data\n|\u2500\u2500 manifest\n|\u2500\u2500 task1\n|   \u2514\u2500\u2500clarity_data\n|       |\u2500\u2500 metadata\n|       |\u2500\u2500 train (use CEC2)\n|       \u2514\u2500\u2500 dev\n|           |\u2500\u2500 scenes\n|           \u2514\u2500\u2500 speaker_adapt\n|\u2500\u2500 task2\n\u2514\u2500\u2500 task3\n"})}),"\n",(0,a.jsx)(t.h2,{id:"recording-setup",children:"Recording setup"}),"\n",(0,a.jsx)(t.p,{children:"Details to appear"}),"\n",(0,a.jsxs)(i.A,{children:[(0,a.jsx)(s.A,{value:"scene",label:"Recording Room",children:(0,a.jsxs)("figure",{id:"fig1",children:[(0,a.jsx)("img",{width:"700",src:(0,o.A)("/img/CEC3/salford_room1.jpg")}),(0,a.jsx)("figcaption",{children:"Figure 1. A view of the recording room with floor markings."})]})}),(0,a.jsx)(s.A,{value:"scene2",label:"...another view",children:(0,a.jsxs)("figure",{id:"fig2",children:[(0,a.jsx)("img",{width:"700",src:(0,o.A)("/img/CEC3/salford_room2.jpg")}),(0,a.jsx)("figcaption",{children:"Figure 2. Recording one of the impulse responses with the Eigenmike EM64."})]})}),(0,a.jsx)(s.A,{value:"scene3",label:"... and another.",children:(0,a.jsxs)("figure",{id:"fig3",children:[(0,a.jsx)("img",{width:"700",src:(0,o.A)("/img/CEC3/salford_pano.jpg")}),(0,a.jsx)("figcaption",{children:"Figure 3. A panoramic shot of the recording room."})]})})]}),"\n",(0,a.jsxs)("figure",{id:"fig4",children:[(0,a.jsx)("img",{width:"700",src:(0,o.A)("/img/CEC3/cec3_salford_rooms.jpg")}),(0,a.jsx)("figcaption",{children:"Schematics showing the 16 room layouts used in the development data. T = Target talker; I = Interferer; L = Listener."})]}),"\n",(0,a.jsx)(t.h2,{id:"the-hearing-aid-signal-simulation",children:"The Hearing Aid signal simulation"}),"\n",(0,a.jsx)(t.p,{children:"Details to appear"}),"\n",(0,a.jsx)(t.h2,{id:"audio-data-format",children:"Audio Data format"}),"\n",(0,a.jsx)(t.p,{children:"All audio data is provided in 16-bit PCM format at a sample rate of 44100 kHz. File names have been designed to be compatible with previous Clarity challenges. For each scene the following audio files are provided:"}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-text",children:"- <SCENE_ID>_mix_CH1.wav - the left and right stereo pair from the front microphone.\n- <SCENE_ID>_mix_CH2.wav - the left and right stereo pair from the middle microphone.\n- <SCENE_ID>_mix_CH3.wav - the left and right stereo pair from the back microphone.\n- <SCENE_ID>_hr.wav - the head rotation signal\n- <SCENE_ID>_reference.wav - the signal to be used as the reference for HASPI evaluation.\n"})}),"\n",(0,a.jsx)(t.h2,{id:"metadata-formats",children:"Metadata Formats"}),"\n",(0,a.jsx)(t.p,{children:"The following metadata files are provided"}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-text",children:"# The description of the scenes\n- scenes.dev.json - metadata for the dev scenes\n- rooms.dev.json - metadata for the dev rooms\n- hrir_data.json - HRIRs using in the simulation\n\n# Listener information\n- scenes_listeners.dev.json - the listeners/scene pairings to for the standard development set\n- listeners.json - the audiograms of the listeners\n\n# Materials used to make up the scenes\n- masker_music_list.json - the list of music interferers\n- masker_nonspeech_list.json - the list of non-speech interferers\n- masker_speech_list.json - the list of speech interferers\n- target_speech_list.json - the list target utterances\n"})}),"\n",(0,a.jsxs)(t.p,{children:["Most of these files follow the same format as in CEC2. The most important are the ",(0,a.jsx)(t.code,{children:"scenes.json"})," and ",(0,a.jsx)(t.code,{children:"rooms.json"})," files and these are described below."]}),"\n",(0,a.jsxs)(t.p,{children:["The ",(0,a.jsx)(t.code,{children:"room"})," describes the locations of the three loudspeakers and the microphone. There are 16 different 'rooms' each describing a different loudspeaker and microphone layout (as shown in the earlier figure). The 'scenes' are represented by a 'room' (i.e., a loudspeaker configuration) and a description of the target and interferers and which of the loudspeakers they were played from. Note, there is a one-to-many relationship between rooms and scenes, i.e., each room is re-used in multiple scenes although not always with the same selection of interferer locations."]}),"\n",(0,a.jsxs)(t.p,{children:["The ",(0,a.jsx)(t.code,{children:"room"})," and ",(0,a.jsx)(t.code,{children:"scene"})," metadata files are described in more detail below."]}),"\n",(0,a.jsx)(t.h3,{id:"the-room-metadata",children:"The Room Metadata"}),"\n",(0,a.jsx)(t.p,{children:"The room metadata is stored in a JSON file as a list of dictionaries, with one dictionary representing each room. There are 16 room layouts released for development data. A separate set of 15 will be used for evaluation. The metadata for the evaluation set will remain hidden."}),"\n",(0,a.jsx)(t.p,{children:"The format is as follows:"}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-json",children:'[\n  {\n    "name": "R001",  // The Room identifier (R001 to R080)\n    "dimensions": "5.0x5.0x2.0",  // Approximate room dimensions (fixed)\n     "target": { // The target (i.e., the talker position)\n      "position": [ // The target position\n        3.0,\n        4.2,\n        1.2  // Heights are either 1.2 or 1.6 and target, listener and inferferer heights are always match\n      ],\n      "view_vector": [ // The target direction - will be towards the listener\n        -0.179,\n        0.984,\n        0.0\n      ]\n    },\n    "listener": { // The listener (i.e., the microphone position)\n      "position": [ // The listener position\n        3.4,\n        2.0,\n        1.2\n      ],\n      "view_vector": [ // The listener default view direction\n        0.179,\n        -0.984,\n        0.0\n      ]\n    },\n    "interferers": [ // A list of 3 interferer positions\n      {\n        "position": [\n          2.2,\n          2.0,\n          1.2\n        ]\n      }, // ... followed by two more positions \n    ]\n  },\n  ... //  more rooms \n]\n'})}),"\n",(0,a.jsx)(t.h3,{id:"the-scene-metadata",children:"The Scene Metadata"}),"\n",(0,a.jsx)(t.p,{children:"The scene metadata is stored in a JSON file as a list of dictionaries with one dictionary for each scene. There are 2500 scenes in the development set. A further 1500 have been retained for the final evaluation and these will use a different set of room layouts."}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-json",children:'[\n  {\n    "dataset": "dev", // The dataset (dev or eval)\n    "room": "R20001", // The room identifier (R20001 to R20016) corresponds to R001 to R016 in the rooms metadata\n    "scene": "S06001", // The Scene ID  (S6001 to S8500)\n    "target": {\n      "name": "T030_A08_01034", // The utterance ID which starts with the talker ID (T001 to T040)\n      "time_start": 80491, // The sample at which the target starts\n      "time_end": 214114 // The sample at which the target ends\n    },\n    "duration": 258214, // The duration of the scene in samples\n    "interferers": [ // Either 2 or 3 interferers in positions 1, 2 and/or 3\n      {\n        "position": 1, // The loudspeaker number (indexed 1 to 3). The location is in the rooms metadata. \n        "time_start": 0, // The sample at which the interferer starts (always 0)\n        "time_end": 258214, // The sample at which the interferer ends (always the end of the scene)\n        "type": "music", // The type of interferer (speech, music, noise)\n        "name": "51/662051.low.mp3",   // The interferer ID\n        "offset": 2563402 // The offset of the interferer in the complete audio file\n      },\n      // ... followed by one or two more interferers\n    ],\n    "SNR": -9.5306,  // The SNR of the target signal (-12 to 6 dB)\n    "listener": {\n      "rotation": [ // Describes a rotation in the horizontal plane\n        {\n          "sample": 74252.5369, // The time (in samples) at which the rotation starts\n          "angle": 71.2240 // The initialial angle in degrees\n        },\n        {\n          "sample": 82883.5369,  // The time  (in samples) at which the rotation starts\n          "angle": 97.4871 // The final angle degrees\n        }\n      ],\n      "hrir_filename": [ // The HRIR used to simulate the hearing aid inputs\n        "BuK-ED",  // The \'ear drum\' HRIR\n        "BuK-BTE_fr", // The front microphone HRIR\n        "BuK-BTE_mid",  // The middle microphone HRIR\n        "BuK-BTE_rear"  // The rear microphone HRIR\n      ]\n    }\n  },\n // ... more scenes\n]\n'})}),"\n",(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsxs)(t.li,{children:["All times in the ",(0,a.jsx)(t.code,{children:"scenes.json"})," file are measured in samples at 44100 Hz."]}),"\n",(0,a.jsxs)(t.li,{children:["In order to simulate the hearing aid signals, the HRIRs are taken from the  ",(0,a.jsx)(t.a,{href:"https://uol.de/mediphysik/downloads/hearingdevicehrtfs",children:"OlHeadHRTF database"})," with permission . Different scenes have used different heads as indicated by the ",(0,a.jsx)(t.code,{children:"hrir_filename"})," field."]}),"\n"]})]})}function f(e={}){const{wrapper:t}={...(0,r.R)(),...e.components};return t?(0,a.jsx)(t,{...e,children:(0,a.jsx)(m,{...e})}):m(e)}},19365:(e,t,n)=>{n.d(t,{A:()=>s});n(96540);var a=n(34164);const r={tabItem:"tabItem_Ymn6"};var i=n(74848);function s(e){let{children:t,hidden:n,className:s}=e;return(0,i.jsx)("div",{role:"tabpanel",className:(0,a.A)(r.tabItem,s),hidden:n,children:t})}},11470:(e,t,n)=>{n.d(t,{A:()=>T});var a=n(96540),r=n(34164),i=n(23104),s=n(56347),o=n(205),l=n(57485),d=n(31682),c=n(89466);function h(e){return a.Children.toArray(e).filter((e=>"\n"!==e)).map((e=>{if(!e||(0,a.isValidElement)(e)&&function(e){const{props:t}=e;return!!t&&"object"==typeof t&&"value"in t}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}function u(e){const{values:t,children:n}=e;return(0,a.useMemo)((()=>{const e=t??function(e){return h(e).map((e=>{let{props:{value:t,label:n,attributes:a,default:r}}=e;return{value:t,label:n,attributes:a,default:r}}))}(n);return function(e){const t=(0,d.X)(e,((e,t)=>e.value===t.value));if(t.length>0)throw new Error(`Docusaurus error: Duplicate values "${t.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[t,n])}function m(e){let{value:t,tabValues:n}=e;return n.some((e=>e.value===t))}function f(e){let{queryString:t=!1,groupId:n}=e;const r=(0,s.W6)(),i=function(e){let{queryString:t=!1,groupId:n}=e;if("string"==typeof t)return t;if(!1===t)return null;if(!0===t&&!n)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return n??null}({queryString:t,groupId:n});return[(0,l.aZ)(i),(0,a.useCallback)((e=>{if(!i)return;const t=new URLSearchParams(r.location.search);t.set(i,e),r.replace({...r.location,search:t.toString()})}),[i,r])]}function p(e){const{defaultValue:t,queryString:n=!1,groupId:r}=e,i=u(e),[s,l]=(0,a.useState)((()=>function(e){let{defaultValue:t,tabValues:n}=e;if(0===n.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(t){if(!m({value:t,tabValues:n}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${t}" but none of its children has the corresponding value. Available values are: ${n.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return t}const a=n.find((e=>e.default))??n[0];if(!a)throw new Error("Unexpected error: 0 tabValues");return a.value}({defaultValue:t,tabValues:i}))),[d,h]=f({queryString:n,groupId:r}),[p,g]=function(e){let{groupId:t}=e;const n=function(e){return e?`docusaurus.tab.${e}`:null}(t),[r,i]=(0,c.Dv)(n);return[r,(0,a.useCallback)((e=>{n&&i.set(e)}),[n,i])]}({groupId:r}),v=(()=>{const e=d??p;return m({value:e,tabValues:i})?e:null})();(0,o.A)((()=>{v&&l(v)}),[v]);return{selectedValue:s,selectValue:(0,a.useCallback)((e=>{if(!m({value:e,tabValues:i}))throw new Error(`Can't select invalid tab value=${e}`);l(e),h(e),g(e)}),[h,g,i]),tabValues:i}}var g=n(92303);const v={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var b=n(74848);function x(e){let{className:t,block:n,selectedValue:a,selectValue:s,tabValues:o}=e;const l=[],{blockElementScrollPositionUntilNextRender:d}=(0,i.a_)(),c=e=>{const t=e.currentTarget,n=l.indexOf(t),r=o[n].value;r!==a&&(d(t),s(r))},h=e=>{let t=null;switch(e.key){case"Enter":c(e);break;case"ArrowRight":{const n=l.indexOf(e.currentTarget)+1;t=l[n]??l[0];break}case"ArrowLeft":{const n=l.indexOf(e.currentTarget)-1;t=l[n]??l[l.length-1];break}}t?.focus()};return(0,b.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,r.A)("tabs",{"tabs--block":n},t),children:o.map((e=>{let{value:t,label:n,attributes:i}=e;return(0,b.jsx)("li",{role:"tab",tabIndex:a===t?0:-1,"aria-selected":a===t,ref:e=>l.push(e),onKeyDown:h,onClick:c,...i,className:(0,r.A)("tabs__item",v.tabItem,i?.className,{"tabs__item--active":a===t}),children:n??t},t)}))})}function j(e){let{lazy:t,children:n,selectedValue:r}=e;const i=(Array.isArray(n)?n:[n]).filter(Boolean);if(t){const e=i.find((e=>e.props.value===r));return e?(0,a.cloneElement)(e,{className:"margin-top--md"}):null}return(0,b.jsx)("div",{className:"margin-top--md",children:i.map(((e,t)=>(0,a.cloneElement)(e,{key:t,hidden:e.props.value!==r})))})}function w(e){const t=p(e);return(0,b.jsxs)("div",{className:(0,r.A)("tabs-container",v.tabList),children:[(0,b.jsx)(x,{...e,...t}),(0,b.jsx)(j,{...e,...t})]})}function T(e){const t=(0,g.A)();return(0,b.jsx)(w,{...e,children:h(e.children)},String(t))}},28453:(e,t,n)=>{n.d(t,{R:()=>s,x:()=>o});var a=n(96540);const r={},i=a.createContext(r);function s(e){const t=a.useContext(i);return a.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function o(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:s(e.components),a.createElement(i.Provider,{value:t},e.children)}}}]);