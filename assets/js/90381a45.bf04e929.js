(self.webpackChunkclarity_cec_1=self.webpackChunkclarity_cec_1||[]).push([[261],{8215:function(e,t,a){"use strict";var i=a(7294);t.Z=function(e){var t=e.children,a=e.hidden,n=e.className;return i.createElement("div",{role:"tabpanel",hidden:a,className:n},t)}},1395:function(e,t,a){"use strict";a.d(t,{Z:function(){return u}});var i=a(7294),n=a(944),r=a(6010),o="tabItem_1uMI",l="tabItemActive_2DSg";var s=37,c=39;var u=function(e){var t=e.lazy,a=e.block,u=e.defaultValue,d=e.values,p=e.groupId,m=e.className,h=(0,n.Z)(),g=h.tabGroupChoices,f=h.setTabGroupChoices,b=(0,i.useState)(u),k=b[0],v=b[1],w=i.Children.toArray(e.children),y=[];if(null!=p){var _=g[p];null!=_&&_!==k&&d.some((function(e){return e.value===_}))&&v(_)}var N=function(e){var t=e.currentTarget,a=y.indexOf(t),i=d[a].value;v(i),null!=p&&(f(p,i),setTimeout((function(){var e,a,i,n,r,o,s,c;(e=t.getBoundingClientRect(),a=e.top,i=e.left,n=e.bottom,r=e.right,o=window,s=o.innerHeight,c=o.innerWidth,a>=0&&r<=c&&n<=s&&i>=0)||(t.scrollIntoView({block:"center",behavior:"smooth"}),t.classList.add(l),setTimeout((function(){return t.classList.remove(l)}),2e3))}),150))},T=function(e){var t,a;switch(e.keyCode){case c:var i=y.indexOf(e.target)+1;a=y[i]||y[0];break;case s:var n=y.indexOf(e.target)-1;a=y[n]||y[y.length-1]}null==(t=a)||t.focus()};return i.createElement("div",{className:"tabs-container"},i.createElement("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,r.Z)("tabs",{"tabs--block":a},m)},d.map((function(e){var t=e.value,a=e.label;return i.createElement("li",{role:"tab",tabIndex:k===t?0:-1,"aria-selected":k===t,className:(0,r.Z)("tabs__item",o,{"tabs__item--active":k===t}),key:t,ref:function(e){return y.push(e)},onKeyDown:T,onFocus:N,onClick:N},a)}))),t?(0,i.cloneElement)(w.filter((function(e){return e.props.value===k}))[0],{className:"margin-vert--md"}):i.createElement("div",{className:"margin-vert--md"},w.map((function(e,t){return(0,i.cloneElement)(e,{key:t,hidden:e.props.value!==k})}))))}},6984:function(e,t,a){"use strict";a.r(t),a.d(t,{frontMatter:function(){return l},metadata:function(){return s},toc:function(){return c},default:function(){return d}});var i=a(2122),n=a(9756),r=(a(7294),a(3905)),o=(a(1395),a(8215),["components"]),l={id:"cec1_software",title:"The Software",sidebar_label:"The Software",sidebar_position:6},s={unversionedId:"cec1_software",id:"cec1_software",isDocsHomePage:!1,title:"The Software",description:"The following software is available to download:",source:"@site/docs/cec1_software.mdx",sourceDirName:".",slug:"/cec1_software",permalink:"/clarity_CEC1_doc/docs/cec1_software",editUrl:"https://github.com/claritychallenge/clarity_CEC1_doc/edit/master/docs/cec1_software.mdx",version:"current",sidebar_label:"The Software",sidebarPosition:6,frontMatter:{id:"cec1_software",title:"The Software",sidebar_label:"The Software",sidebar_position:6},sidebar:"tutorialSidebar",previous:{title:"The CEC1 Data",permalink:"/clarity_CEC1_doc/docs/cec1_data"},next:{title:"The Rules",permalink:"/clarity_CEC1_doc/docs/cec1_rules"}},c=[{value:"A. Scene generator",id:"a-scene-generator",children:[]},{value:"B. Baseline hearing aid processor",id:"b-baseline-hearing-aid-processor",children:[]},{value:"C. Hearing Loss model",id:"c-hearing-loss-model",children:[]},{value:"D. Speech Intelligibility model",id:"d-speech-intelligibility-model",children:[]}],u={toc:c};function d(e){var t=e.components,a=(0,n.Z)(e,o);return(0,r.kt)("wrapper",(0,i.Z)({},u,a,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("p",null,"The following software is available to download:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Scene generator"),(0,r.kt)("li",{parentName:"ul"},"Hearing aid processor baseline"),(0,r.kt)("li",{parentName:"ul"},"Hearing loss model"),(0,r.kt)("li",{parentName:"ul"},"Speech intelligibility model")),(0,r.kt)("p",null,"The code is a Python package and accompanying unix shell scripts, with the facility to process a single scene or to bulk process the complete Clarity dataset."),(0,r.kt)("h2",{id:"a-scene-generator"},"A. Scene generator"),(0,r.kt)("p",null,"Fully open-source python code for generating hearing aid inputs for each scene"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Inputs"),": target and interferer signals, BRIRs, RAVEN project (rpf) files, scene description JSON files"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Outputs"),": Mixed target+interferer signals for each hearing aid channel, direct path (simulating a measurement close to the eardrum). Reverberated pre-mixed signals can also be optionally generated.")),(0,r.kt)("h2",{id:"b-baseline-hearing-aid-processor"},"B. Baseline hearing aid processor"),(0,r.kt)("p",null,"The baseline hearing aid processor is based on openMHA. The python code configures openMHA with a Camfit compressive fitting for a specific listener\u2019s audiogram. This includes a python implementation of the Camfit compressive prescription and python code for driving openMHA."),(0,r.kt)("p",null,"This configuration of openMHA includes multiband dynamic compression and non-adaptive differential processing. The intention was to produce a basic hearing aid without various aspects of signal processing that are common in high-end hearing aids, but tend to be implemented in proprietary forms so cannot be replicated exactly."),(0,r.kt)("p",null,"The main inputs and outputs for the processor are as follows:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Inputs"),": Mixed scene signals for each hearing aid channel, a listener ID drawn from scene-listener pairs identified in \u2018scenes_listeners.json\u2019 and an entry in the listener metadata json file \u2018listeners.json\u2019 for that ID"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Outputs"),": The stereo hearing aid output signal, ",(0,r.kt)("inlineCode",{parentName:"li"},"<scene>_<listener>_HA-output.wav"))),(0,r.kt)("h2",{id:"c-hearing-loss-model"},"C. Hearing Loss model"),(0,r.kt)("p",null,"Open-source python implementation of the Cambridge Auditory Group Moore/Stone/Baer/Glasberg hearing loss model."),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Inputs"),": A stereo wav audio signal, e.g., the output of the baseline hearing aid processor, and a set of audiograms (both L and R ears)."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Outputs"),":  The signal after simulating the hearing loss as specified by the set of audiograms (stereo wav file), ",(0,r.kt)("inlineCode",{parentName:"li"},"<scene>_<listener>_HL-output.wav"))),(0,r.kt)("h2",{id:"d-speech-intelligibility-model"},"D. Speech Intelligibility model"),(0,r.kt)("p",null,"Python implementation of a binaural intelligibility model, Modified Binaural Short-Time Objective Intelligibility (MBSTOI). This is an experimental baseline tool that will be used in the stage 1 evaluation of entrants (see Rules). Note that MBSTOI requires signal time-alignment (and alignment within one-third octave bands)."),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Inputs"),":  HL-model output signals, audiogram, reference target signal (i.e., the premixed target signal convolved with the BRIR with the reflections \u201cturned off\u201d, specified as \u2018target_anechoic\u2019), (scene metadata)"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Outputs"),": predicted intelligibility score")))}d.isMDXComponent=!0}}]);